import{_ as a,V as e,W as i,$ as l,X as r,a1 as o}from"./framework-8aef05fa.js";const k={},d=r("p",null,"本章主要介绍Kafka面试题",-1),h=o('<h2 id="_1-为什么要使用kafka" tabindex="-1"><a class="header-anchor" href="#_1-为什么要使用kafka" aria-hidden="true">#</a> 1. 为什么要使用Kafka</h2><blockquote><p>Kafka的作用，好处，应用场景</p></blockquote><ol><li>缓冲和削峰： 上游突发流量，下游性能不足，Kafka缓冲。</li><li>应用解耦：作为接口层，解耦重要业务流程</li><li>异步通信：系统需要时处理</li></ol><h2 id="_2-kafka消费过的消息如何再消费" tabindex="-1"><a class="header-anchor" href="#_2-kafka消费过的消息如何再消费" aria-hidden="true">#</a> 2. Kafka消费过的消息如何再消费</h2><p>offset信息是记录在zk中的，可以在redis自己记录一份offset checkpoint，使用该数据进行offset重设。</p><h2 id="_3-kafka数据是放在哪里的-为什么速度快" tabindex="-1"><a class="header-anchor" href="#_3-kafka数据是放在哪里的-为什么速度快" aria-hidden="true">#</a> 3. Kafka数据是放在哪里的，为什么速度快</h2><ol><li>Kafka采用的磁盘存储</li><li>速度快是因为： <ol><li>Kafka是分布式集群，并行度高</li><li>读数据采用稀疏索引，可以快速定位</li><li>顺序写磁盘</li><li>页缓存+零拷贝技术</li></ol></li></ol><h2 id="_4-kafka查找过程" tabindex="-1"><a class="header-anchor" href="#_4-kafka查找过程" aria-hidden="true">#</a> 4. Kafka查找过程</h2><ol><li>基于位移的查找 <ol><li>连接zk，拿到对应topic的partition信息和Leader信息</li><li>根据需要查找的offset根据二分查找定位了目标segment文件</li><li>在index文件中，通过物理偏移地址找到最近的一个相对偏移</li><li>在log文件中，从相对偏移位置开始，顺序查找到offset位置</li></ol></li><li>基于时间的查找</li></ol><h2 id="_5-kafka怎么保证数据不丢失" tabindex="-1"><a class="header-anchor" href="#_5-kafka怎么保证数据不丢失" aria-hidden="true">#</a> 5. Kafka怎么保证数据不丢失</h2><ol><li>生产者</li></ol><p><strong>ACK机制</strong></p><p>0：生产者不等待broker的同步完成确认</p><p>1：等待Leader成功收到，在发送下一条</p><p>-1：等到follower也同步完成</p><p>如果是同步模式，设为0的时候风险很大，设为1也会随着Leader宕机而丢失数据，-1最保险</p><p>如果是异步模式：考虑ack(回调)、时间阈值和消息的数量阈值</p><ol start="2"><li>消费者数据不丢</li></ol><p>因为offset信息并不是每次消费后的记录的，因此会重复消费，但不会丢数据</p><p>例外：两个不同功能的消费者用了同一个groupid</p><ol start="3"><li>broker数据不丢</li></ol><p>设置副本数量</p><h2 id="_6-采集数据为什么选择kafka" tabindex="-1"><a class="header-anchor" href="#_6-采集数据为什么选择kafka" aria-hidden="true">#</a> 6. 采集数据为什么选择Kafka</h2><p>Flume 是一个专用工具被设计为旨在往 HDFS，HBase 发送数据。它对 HDFS 有特殊的优化，并且集成了 Hadoop 的安全特性。</p><p>Cloudera 建议如果数据被多个系统消费的话，使用 kafka;如果数据被 设计给 Hadoop 使用，使用 Flume</p><h2 id="_7-kafka重启是否会导致数据丢失" tabindex="-1"><a class="header-anchor" href="#_7-kafka重启是否会导致数据丢失" aria-hidden="true">#</a> 7. Kafka重启是否会导致数据丢失</h2><ol><li>数据在磁盘，一般不会丢失</li><li>如果Leader挂掉了，之前follower数据未完全同步，选举成为新的Leader后，其余follower会截掉高于High watermark的数据</li></ol><h2 id="_8-kafka宕机了如何解决" tabindex="-1"><a class="header-anchor" href="#_8-kafka宕机了如何解决" aria-hidden="true">#</a> 8. Kafka宕机了如何解决</h2><ol><li>先考虑业务是否受到影响</li><li>节点排错和恢复</li></ol><h2 id="_9-kafka为什么不支持读写分离" tabindex="-1"><a class="header-anchor" href="#_9-kafka为什么不支持读写分离" aria-hidden="true">#</a> 9. Kafka为什么不支持读写分离</h2><p>Kafka读写都是和Leader副本进行交互的，是主写主读生成消费模型</p><p>读写分离的问题</p><ol><li>数据一致性问题</li><li>延时问题，对延时敏感的应用而言，不适用</li></ol><p>主读主写的优点</p><ol><li>简化代码的逻辑实现</li><li>没有延时的影响</li><li>在副本稳定的情况下，不会出现数据不一致的情况</li></ol><h2 id="_10-kafka数据分区和消费者的关系" tabindex="-1"><a class="header-anchor" href="#_10-kafka数据分区和消费者的关系" aria-hidden="true">#</a> 10. Kafka数据分区和消费者的关系</h2><p>一个分区只能由同一个消费者组内的一个消费者进行消费，不同消费者组不影响。</p><h2 id="_11-kafka内部如何保证顺序-外部组会如何保证消费者顺序" tabindex="-1"><a class="header-anchor" href="#_11-kafka内部如何保证顺序-外部组会如何保证消费者顺序" aria-hidden="true">#</a> 11. kafka内部如何保证顺序，外部组会如何保证消费者顺序</h2><p>Kafka只能保证partition内是有序的。</p><p>一定要做的话就把需要有序的数据打到同一个partition中</p><h2 id="_12-kafka数据积压-消费能力不足怎么办" tabindex="-1"><a class="header-anchor" href="#_12-kafka数据积压-消费能力不足怎么办" aria-hidden="true">#</a> 12. Kafka数据积压，消费能力不足怎么办</h2><ol><li>增加分区数量，提高消费者的数量</li><li>下游处理的不及时的话，可以提高每批次拉取的数量</li></ol><h2 id="_13-kafka单条日志传输大小" tabindex="-1"><a class="header-anchor" href="#_13-kafka单条日志传输大小" aria-hidden="true">#</a> 13. Kafka单条日志传输大小</h2><p>默认1M</p>',44);function f(t,n){return e(),i("div",null,[d,l(" more "),h])}const p=a(k,[["render",f],["__file","Kafka大厂面试题.html.vue"]]);export{p as default};
